{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from labml_helpers.module import Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BN depends on a basic concept called **whitening** \n",
    "    - It is known that whitening improves speed and convergence. \n",
    "    - Here, we linearly transform inputs to have zero mean, unit variance, and be uncorrelated\n",
    "    - But it can be computationally expensive because you need to de-correlate and the gradients must flow through the full whitening calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(Module):\n",
    "    \"\"\"\n",
    "        channels: is the num of features in the input\n",
    "        eps: is used for numerical stability (avoiding zero sqrt)\n",
    "        momentum: is the momentum in taking the exponential moving average\n",
    "        affine: is whether to scale and shift the normalized value\n",
    "        track_running_stats: is whether to calculate the moving averages or mean and variance\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int, *, eps: float=1e-5, momentum: float=0.1, affine: bool=True, track_running_stats: bool=True):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.affine = affine\n",
    "        self.track_running_stats = track_running_stats\n",
    "\n",
    "        \"\"\"\n",
    "            create params gamma and beta for scale and shift \n",
    "        \"\"\"    \n",
    "        if self.affine:\n",
    "            self.scale = nn.Parameter(torch.ones(channels))\n",
    "            self.shift = nn.Parameter(torch.zeros(channels))\n",
    "        \n",
    "        \"\"\"\n",
    "            create buffers to store exponential moving averages of mean and variance \n",
    "        \"\"\"\n",
    "        if self.track_running_stats:\n",
    "            self.register_buffer('exp_mean', torch.zeros(channels))\n",
    "            self.register_buffer('exp_var', torch.ones(channels))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "            x is a tensor of shape [batch_size, channels, *].\n",
    "            * denotes any number of (possibly 0) dimensions.\n",
    "            E.g., in an image (2D) convolution this will be [batch_size, channels, height, width]\n",
    "        \"\"\"\n",
    "        x_shape = x.shape\n",
    "        batch_size = x_shape[0]\n",
    "        assert self.channels == x.shape[1]\n",
    "        x = x.view(batch_size, self.channels, -1) # NOTE: reshape into [batch_size, channels, n]\n",
    "        \n",
    "        if self.training or not self.track_running_stats:\n",
    "\n",
    "            mean = x.mean(dim=[0, 2])\n",
    "            mean_x2 = (x ** 2).mean(dim=[0, 2]) # NOTE: calculate the squared mean across first and last dimension\n",
    "            var = mean_x2 - mean**2\n",
    "\n",
    "            if self.training and self.track_running_stats:\n",
    "                self.exp_mean = (1 - self.momentum) * self.exp_mean + self.momentum * mean\n",
    "                self.exp_var = (1 - self.momentum) * self.exp_var + self.momentum * var\n",
    "        \n",
    "        else:\n",
    "            mean = self.exp_mean\n",
    "            var = self.exp_var\n",
    "        \n",
    "        x_norm = (x - mean.view(1, -1, 1)) / torch.sqrt(var + self.eps).view(1, -1, 1) # NOTE: normalize\n",
    "\n",
    "        if self.affine:\n",
    "            x_norm = self.scale.view(1, -1, 1) * x_norm + self.shift.view(1, -1, 1) # NOTE: scale and shift\n",
    "        \n",
    "        return x_norm.view(x_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test():\n",
    "    from labml.logger import inspect\n",
    "    \n",
    "    x = torch.zeros([2, 3, 2, 4])\n",
    "    inspect(x.shape)\n",
    "    bn = BatchNorm(3)\n",
    "\n",
    "    x = bn(x)\n",
    "    inspect(x.shape)\n",
    "    inspect(bn.exp_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
