{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of **Batch Normalization**:\n",
    "- You need to maintain running means\n",
    "- Tricky for RNNs. Do you need normalization for each step?\n",
    "- Doens't work with small batch sizes\n",
    "- Need to compute means and variances across devices in distributed training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Normalization\n",
    "- Layer Normalization is a simpler normalization method that works on a wider range of settings\n",
    "- It transforms the inputs to have zero mean and variance **across all features** \n",
    "- Note: BN fixes the zero mean and unit variance **for each element**\n",
    "- Layer normalization does it for each batch across all elements!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "import torch\n",
    "from torch import nn, Size\n",
    "from labml_helpers.module import Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `normalized_shape` $S$ is the shaoe of the elements (except the batch). \n",
    "- `eps` is $\\epsilon$, used for numerical stability\n",
    "- `elementwise_affine` is whether to scale and shift the normalized value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(Module):\n",
    "    def __init__(self, normalized_shape: Union[int, List[int], Size], *, eps: float=1e-5, elementwise_affine: bool=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # NOTE: Convert normalized_shape to torch.Size\n",
    "        if isinstance(normalized_shape, int):\n",
    "            normalized_shape = torch.Size([normalized_shape])\n",
    "        elif isinstance(normalized_shape, list):\n",
    "            normalized_shape = torch.Size(normalized_shape)\n",
    "        assert isinstance(normalized_shape, torch.Size)\n",
    "\n",
    "        self.normalized_shape = normalized_shape\n",
    "        self.eps = eps\n",
    "        self.elementwise_affine = elementwise_affine\n",
    "\n",
    "        # NOTE: Create parameters y and ÃŸ for gain and bias\n",
    "        if self.elementwise_affine:\n",
    "            self.gain = nn.Parameter(torch.ones(normalized_shape))\n",
    "            self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "    \n",
    "    \"\"\" NOTE: x is a tensor of shape [*, S[0], S[1], ..., S[n]]. \n",
    "             * could be any number of dimensions. For example, in \n",
    "             an NLP task this will be [seq_len, batch_size, features] \"\"\"\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # NOTE: Sanity check to make sure the shapes match\n",
    "        assert self.normalized_shape == x.shape[-len(self.normalized_shape):]\n",
    "        dims = [-(i+1) for i in range(len(self.normalized_shape))]\n",
    "        mean = x.mean(dim=dims, keepdim=True)\n",
    "        mean_x2 = (x**2).mean(dim=dims, keepdim=True)\n",
    "        var = mean_x2 - mean ** 2 # NOTE: Var(x) = E[X^2] - E[X]^2\n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        if self.elementwise_affine:\n",
    "            x_norm = self.gain * x_norm + self.bias\n",
    "        return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test():\n",
    "    from labml.logger import inspect\n",
    "\n",
    "    x = torch.zeros([2, 3, 2, 4])\n",
    "    inspect(x.shape)\n",
    "    ln = LayerNorm(x.shape[2:])\n",
    "\n",
    "    x = ln(x)\n",
    "    inspect(x.shape)\n",
    "    inspect(ln.gain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #60C6C8\">0: </span><strong>2</strong>\n",
       "<span style=\"color: #60C6C8\">1: </span><strong>3</strong>\n",
       "<span style=\"color: #60C6C8\">2: </span><strong>2</strong>\n",
       "<span style=\"color: #60C6C8\">3: </span><strong>4</strong>\n",
       "Total <span style=\"color: #208FFB\">4</span> item(s)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
